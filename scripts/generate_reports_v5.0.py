#!/usr/bin/env python3
"""
å¥åº·æŠ¥å‘Šç”Ÿæˆå™¨ - V5.0 ä¸ªæ€§åŒ–ç‰ˆ
ä½¿ç”¨personalized_ai_analyzerç”Ÿæˆè¯¦ç»†ã€ä¸ªæ€§åŒ–çš„åˆ†æ
"""
import json
import os
import sys
sys.path.insert(0, '/Users/jimmylu/.openclaw/workspace-health/scripts')

from datetime import datetime, timedelta
from pathlib import Path
from playwright.sync_api import sync_playwright
from personalized_ai_analyzer import generate_personalized_analysis, PersonalizedAIAnalyzer

HOME = Path.home()
HEALTH_DIR = HOME / 'æˆ‘çš„äº‘ç«¯ç¡¬ç›˜' / 'Health Auto Export' / 'Health Data'
WORKOUT_DIR = HOME / 'æˆ‘çš„äº‘ç«¯ç¡¬ç›˜' / 'Health Auto Export' / 'Workout Data'
TEMPLATE_DIR = HOME / '.openclaw' / 'workspace-health' / 'templates'
OUTPUT_DIR = HOME / '.openclaw' / 'workspace' / 'shared' / 'health-reports' / 'upload'
CACHE_DIR = HOME / '.openclaw' / 'workspace-health' / 'cache' / 'daily'

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# ========== æ ‡å‡†åŒ–çš„è¯„åˆ†è®¡ç®—å‡½æ•° ==========
def calc_recovery_score(hrv, resting_hr, sleep_hours):
    score = 70
    if hrv and hrv > 50: score += 10
    if resting_hr and resting_hr < 65: score += 10
    if sleep_hours and sleep_hours > 7: score += 10
    return min(100, score)

def calc_sleep_score(sleep_hours, deep_hours, rem_hours):
    if not sleep_hours or sleep_hours == 0: return 0
    if sleep_hours < 6: score = 30
    elif sleep_hours < 7: score = 50
    elif sleep_hours < 8: score = 70
    else: score = 80
    if deep_hours and deep_hours >= 1.5: score += 10
    if rem_hours and rem_hours >= 1.5: score += 10
    return min(100, score)

def calc_exercise_score(steps, has_workout, energy_kcal):
    score = 50
    if steps >= 10000: score += 25
    elif steps >= 7000: score += 15
    elif steps >= 5000: score += 10
    if has_workout: score += 15
    if energy_kcal >= 500: score += 10
    return min(100, score)

# ========== æ•°æ®æå–å‡½æ•°ï¼ˆä¸V4.5ç›¸åŒï¼‰ ==========
def extract_metric_avg(metrics, name):
    metric = metrics.get(name, {})
    values = [d.get('qty', 0) for d in metric.get('data', []) if 'qty' in d]
    return (sum(values) / len(values), len(values)) if values else (None, 0)

def extract_metric_sum(metrics, name):
    metric = metrics.get(name, {})
    values = [d.get('qty', 0) for d in metric.get('data', []) if 'qty' in d]
    return (sum(values), len(values)) if values else (0, 0)

def parse_health_data(date_str):
    filepath = HEALTH_DIR / f'HealthAutoExport-{date_str}.json'
    if not filepath.exists(): return None
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return {m['name']: m for m in data.get('data', {}).get('metrics', [])}

def parse_workout_data(date_str):
    filepath = WORKOUT_DIR / f'HealthAutoExport-{date_str}.json'
    if not filepath.exists(): return []
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    workouts = data.get('data', []) if isinstance(data.get('data'), list) else data.get('data', {}).get('workouts', [])
    
    result = []
    for w in workouts:
        energy_list = w.get('activeEnergy', [])
        if isinstance(energy_list, list) and energy_list: total_kj = sum(e.get('qty', 0) for e in energy_list)
        elif isinstance(energy_list, dict): total_kj = energy_list.get('qty', 0)
        else: total_kj = 0
        
        hr_data = w.get('heartRateData', [])
        hr_timeline = [{'time': hr.get('date', '').split(' ')[1][:5] if ' ' in hr.get('date', '') else '',
                       'avg': round(hr.get('Avg', 0)), 'max': hr.get('Max', 0), 'min': hr.get('Min', 0)} 
                      for hr in hr_data if 'Avg' in hr]
        
        if hr_timeline:
            avg_hr_calc = sum(h['avg'] for h in hr_timeline) / len(hr_timeline)
            max_hr_calc = max(h['max'] for h in hr_timeline)
        else: avg_hr_calc = max_hr_calc = None
        
        hr_field = w.get('heartRate', {})
        avg_hr = hr_field.get('avg', {}).get('qty') if isinstance(hr_field, dict) and hr_field.get('avg') else avg_hr_calc
        max_hr = hr_field.get('max', {}).get('qty') if isinstance(hr_field, dict) and hr_field.get('max') else max_hr_calc
        
        result.append({'name': w.get('name', 'æœªçŸ¥è¿åŠ¨'), 'start': w.get('start', '')[:16] if w.get('start') else '',
                      'duration_min': round(w.get('duration', 0) / 60, 1), 'energy_kj': total_kj,
                      'energy_kcal': round(total_kj / 4.184, 0) if total_kj else 0,
                      'avg_hr': round(avg_hr) if avg_hr else None, 'max_hr': round(max_hr) if max_hr else None,
                      'hr_timeline': hr_timeline, 'hr_points': len(hr_timeline)})
    return result

def parse_sleep_data(date_str):
    date = datetime.strptime(date_str, '%Y-%m-%d')
    next_date = (date + timedelta(days=1)).strftime('%Y-%m-%d')
    filepath = HEALTH_DIR / f'HealthAutoExport-{next_date}.json'
    if not filepath.exists(): return None
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    metrics = {m['name']: m for m in data.get('data', {}).get('metrics', [])}
    sleep_metric = metrics.get('sleep_analysis', {})
    if not sleep_metric or not sleep_metric.get('data'): return None
    
    window_start = date.replace(hour=20, minute=0)
    window_end = (date + timedelta(days=1)).replace(hour=12, minute=0)
    
    sleep_records = []
    for sleep in sleep_metric.get('data', []):
        sleep_start_str = sleep.get('sleepStart', '')
        if not sleep_start_str: continue
        try:
            sleep_start = datetime.strptime(sleep_start_str[:19], '%Y-%m-%d %H:%M:%S')
            if window_start <= sleep_start <= window_end:
                asleep = sleep.get('asleep', 0) or sleep.get('totalSleep', 0)
                deep = sleep.get('deep', 0); core = sleep.get('core', 0); rem = sleep.get('rem', 0); awake = sleep.get('awake', 0)
                if asleep == 0 and (deep + core + rem + awake) > 0: asleep = deep + core + rem + awake
                sleep_records.append({'total': asleep, 'deep': deep, 'core': core, 'rem': rem, 'awake': awake,
                                     'sleep_start': sleep_start_str, 'sleep_end': sleep.get('sleepEnd', ''),
                                     'source_file': str(filepath)})
        except: continue
    
    if not sleep_records: return None
    return {'total': round(sum(r['total'] for r in sleep_records), 2),
            'deep': round(sum(r['deep'] for r in sleep_records), 2),
            'core': round(sum(r['core'] for r in sleep_records), 2),
            'rem': round(sum(r['rem'] for r in sleep_records), 2),
            'awake': round(sum(r['awake'] for r in sleep_records), 2),
            'records': sleep_records, 'source_file': sleep_records[0]['source_file']}

def extract_daily_data(date_str):
    metrics = parse_health_data(date_str)
    if not metrics: return None
    
    hrv, hrv_points = extract_metric_avg(metrics, 'heart_rate_variability')
    resting_hr, _ = extract_metric_avg(metrics, 'resting_heart_rate')
    steps, steps_points = extract_metric_sum(metrics, 'step_count')
    distance, _ = extract_metric_sum(metrics, 'walking_running_distance')
    active_energy_kj, _ = extract_metric_sum(metrics, 'active_energy')
    basal_energy_kj, _ = extract_metric_sum(metrics, 'basal_energy_burned')
    floors, _ = extract_metric_sum(metrics, 'flights_climbed')
    stand_min, _ = extract_metric_sum(metrics, 'apple_stand_time')
    
    spo2_raw, spo2_points = extract_metric_avg(metrics, 'blood_oxygen_saturation')
    if spo2_raw and spo2_raw > 1: spo2 = spo2_raw
    elif spo2_raw: spo2 = spo2_raw * 100
    else: spo2 = None
    
    resp_rate, _ = extract_metric_avg(metrics, 'respiratory_rate')
    active_energy_kcal = active_energy_kj / 4.184 if active_energy_kj else 0
    basal_energy_kcal = basal_energy_kj / 4.184 if basal_energy_kj else 0
    
    workouts = parse_workout_data(date_str)
    sleep = parse_sleep_data(date_str)
    
    return {'date': date_str, 'hrv': {'value': round(hrv, 1) if hrv else None, 'points': hrv_points},
            'resting_hr': {'value': round(resting_hr) if resting_hr else None},
            'steps': {'value': int(steps), 'points': steps_points}, 'distance': {'value': round(distance, 2)},
            'active_energy': {'value': round(active_energy_kcal), 'kj': active_energy_kj},
            'basal_energy': {'value': round(basal_energy_kcal), 'kj': basal_energy_kj},
            'floors': int(floors), 'stand_min': int(stand_min),
            'spo2': {'value': round(spo2, 1) if spo2 else None, 'points': spo2_points},
            'resp_rate': {'value': round(resp_rate, 1) if resp_rate else None},
            'workouts': workouts, 'has_workout': len(workouts) > 0, 'sleep': sleep,
            'scores': {'recovery': calc_recovery_score(hrv, resting_hr, sleep['total'] if sleep else 0),
                      'sleep': calc_sleep_score(sleep['total'] if sleep else 0, sleep['deep'] if sleep else 0, sleep['rem'] if sleep else 0) if sleep else 0,
                      'exercise': calc_exercise_score(int(steps) if steps else 0, len(workouts) > 0, active_energy_kcal)}}

def save_cache(data, date_str):
    cache_path = CACHE_DIR / f'{date_str}.json'
    with open(cache_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_cache(date_str):
    cache_path = CACHE_DIR / f'{date_str}.json'
    if cache_path.exists():
        with open(cache_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# ========== å‘¨æŠ¥/æœˆæŠ¥ä¸ªæ€§åŒ–åˆ†æ ==========
def generate_weekly_personalized_analysis(weekly_data, avg_hrv, avg_steps, avg_sleep, workout_days):
    """ç”Ÿæˆå‘¨æŠ¥ä¸ªæ€§åŒ–åˆ†æï¼ˆæ¯éƒ¨åˆ†200-250å­—ï¼‰"""
    
    # è®¡ç®—æ³¢åŠ¨èŒƒå›´
    hrv_values = [d['hrv']['value'] for d in weekly_data if d['hrv']['value']]
    hrv_min, hrv_max = min(hrv_values), max(hrv_values) if hrv_values else (0, 0)
    
    step_values = [d['steps']['value'] for d in weekly_data]
    step_min, step_max = min(step_values), max(step_values) if step_values else (0, 0)
    
    # è¶‹åŠ¿åˆ†æ
    hrv_trend = f"""æœ¬å‘¨HRVå¹³å‡{avg_hrv:.1f}msï¼Œæ³¢åŠ¨èŒƒå›´{hrv_min:.1f}-{hrv_max:.1f}msï¼Œæ ‡å‡†å·®{((hrv_max-hrv_min)/2):.1f}msã€‚

ä»è¶‹åŠ¿çœ‹ï¼Œæœ¬å‘¨HRV{'æ•´ä½“å‘å¥½' if avg_hrv > 50 else 'å¤„äºä¸€èˆ¬æ°´å¹³' if avg_hrv > 45 else 'åä½'}ã€‚

ç»“åˆç¡çœ æ•°æ®ï¼ˆå¹³å‡{avg_sleep:.1f}å°æ—¶ï¼‰ï¼Œ{'å……è¶³ç¡çœ æœ‰åŠ©äºç»´æŒè‰¯å¥½HRV' if avg_sleep >= 7 else 'ç¡çœ ä¸è¶³å¯èƒ½æ˜¯HRVæ³¢åŠ¨çš„å› ç´ ' if avg_sleep < 6 else 'ç¡çœ å¯¹HRVå½±å“éœ€æŒç»­å…³æ³¨'}ã€‚

æ´»åŠ¨é‡æ–¹é¢ï¼ˆæ—¥å‡{int(avg_steps):,}æ­¥ï¼‰ï¼Œ{'é€‚åº¦æ´»åŠ¨æœ‰åŠ©äºHRVç¨³å®š' if 6000 <= avg_steps <= 10000 else 'æ´»åŠ¨é‡åä½æˆ–è¿‡é«˜éƒ½å¯èƒ½å½±å“æ¢å¤'}ã€‚

ä¸‹å‘¨å»ºè®®ï¼š{'ä¿æŒå½“å‰ä½œæ¯ï¼Œå¯å°è¯•å†¥æƒ³ä¼˜åŒ–' if avg_hrv > 50 else 'ä¼˜å…ˆä¿è¯7-8å°æ—¶ç¡çœ ï¼Œé™ä½è®­ç»ƒå¼ºåº¦' if avg_hrv <= 45 else 'å…³æ³¨ç¡çœ è´¨é‡ï¼Œé€‚åº¦å¢åŠ æ´»åŠ¨é‡'}ã€‚"""
    
    activity_trend = f"""æœ¬å‘¨æ—¥å‡æ­¥æ•°{int(avg_steps):,}æ­¥ï¼Œæ³¢åŠ¨èŒƒå›´{step_min:,}-{step_max:,}æ­¥ï¼Œå·¥ä½œæ—¥ä¸å‘¨æœ«å·®å¼‚{abs(step_max-step_min):,}æ­¥ã€‚

ä»æ´»åŠ¨æ¨¡å¼çœ‹ï¼Œ{'æ´»åŠ¨é‡ç›¸å¯¹ç¨³å®š' if step_max - step_min < 5000 else 'å·¥ä½œæ—¥ä¸å‘¨æœ«æ´»åŠ¨é‡å·®å¼‚è¾ƒå¤§ï¼Œå»ºè®®å¹³è¡¡'}ã€‚

{ 'å·²è¾¾åˆ°æ¨èç›®æ ‡ï¼Œæœ‰åŠ©äºç»´æŒå¥åº·ä½“é‡å’Œå¿ƒè¡€ç®¡åŠŸèƒ½' if avg_steps >= 10000 else 'è·ç¦»10000æ­¥ç›®æ ‡æœ‰å·®è·ï¼Œå»ºè®®å¢åŠ æ—¥å¸¸æ­¥è¡Œ' if avg_steps < 8000 else 'æ´»åŠ¨é‡åŸºæœ¬è¾¾æ ‡ï¼Œå»ºè®®ä¿æŒç¨³å®šå¹¶å°è¯•æŒ‘æˆ˜æ›´é«˜ç›®æ ‡'}ã€‚

ç»“åˆè¿åŠ¨è®°å½•ï¼ˆ{workout_days}å¤©ï¼‰ï¼Œ{'ç»“æ„åŒ–è¿åŠ¨é¢‘ç‡è‰¯å¥½' if workout_days >= 3 else 'å»ºè®®å¢åŠ ç»“æ„åŒ–è¿åŠ¨ï¼Œç›®æ ‡æ¯å‘¨3-4æ¬¡'}ã€‚

ä¸‹å‘¨ç›®æ ‡ï¼š{'ç»´æŒå½“å‰æ°´å¹³ï¼Œå°è¯•å¢åŠ è¿åŠ¨å¼ºåº¦' if avg_steps >= 10000 else 'æ—¥å‡æ­¥æ•°æå‡è‡³{int(avg_steps*1.2):,}æ­¥ï¼Œå¢åŠ 1-2æ¬¡ç»“æ„åŒ–è¿åŠ¨' if avg_steps < 8000 else 'ä¿æŒå½“å‰æ°´å¹³ï¼Œå…³æ³¨æ´»åŠ¨å¼ºåº¦'}."""
    
    return hrv_trend, activity_trend

def main():
    dates = ['2026-02-18', '2026-02-19', '2026-02-20', '2026-02-21', '2026-02-22']
    daily_data = {}
    
    print("=" * 60)
    print("å¥åº·æŠ¥å‘Šç”Ÿæˆå™¨ - V5.0 ä¸ªæ€§åŒ–ç‰ˆ")
    print("=" * 60)
    print("\nğŸ†• ä½¿ç”¨ä¸ªæ€§åŒ–AIåˆ†ææ¨¡å—")
    print("- åŸºäºå…·ä½“æ•°æ®ç‚¹ç”Ÿæˆæ´å¯Ÿ")
    print("- æŒ‡æ ‡é—´å…³è”åˆ†æ")
    print("- å¯æ“ä½œçš„ä¸ªæ€§åŒ–å»ºè®®")
    
    # è¯»å–æ¨¡æ¿
    with open(TEMPLATE_DIR / 'DAILY_TEMPLATE_V2.html', 'r', encoding='utf-8') as f:
        daily_template = f.read()
    
    # æå–æ•°æ®
    for date in dates:
        print(f"\nğŸ“… å¤„ç† {date}...")
        data = extract_daily_data(date)
        if data:
            daily_data[date] = data
            save_cache(data, date)
            print(f"  HRV: {data['hrv']['value']:.1f}ms | æ­¥æ•°: {data['steps']['value']:,} | ç¡çœ : {data['sleep']['total']:.1f}h" if data['sleep'] else f"  HRV: {data['hrv']['value']:.1f}ms | æ­¥æ•°: {data['steps']['value']:,} | ç¡çœ : æ— æ•°æ®")
    
    # ç”Ÿæˆ2æœˆ18æ—¥æŠ¥è¡¨
    date_str = '2026-02-18'
    if date_str in daily_data:
        print("\n" + "=" * 60)
        print("ç”Ÿæˆä¸ªæ€§åŒ–åˆ†æ...")
        print("=" * 60)
        
        # å‡†å¤‡å†å²æ•°æ®ï¼ˆå‰4å¤©ä½œä¸ºå†å²ï¼‰
        history = [daily_data[d] for d in dates[:4] if d in daily_data and d != date_str]
        
        # ç”Ÿæˆä¸ªæ€§åŒ–åˆ†æ
        analysis = generate_personalized_analysis(daily_data[date_str], history)
        
        print(f"\nğŸ“ HRVåˆ†æ ({len(analysis['hrv_analysis'])}å­—):")
        print(analysis['hrv_analysis'][:150] + "...")
        
        print(f"\nğŸ˜´ ç¡çœ åˆ†æ ({len(analysis['sleep_analysis'])}å­—):")
        print(analysis['sleep_analysis'][:150] + "...")
        
        print(f"\nğŸƒ è¿åŠ¨åˆ†æ ({len(analysis['workout_analysis'])}å­—):")
        print(analysis['workout_analysis'][:150] + "...")
        
        print(f"\nğŸ’¡ æœ€é«˜ä¼˜å…ˆçº§å»ºè®® ({len(analysis['priority_recommendation']['problem'])}å­—):")
        print(f"æ ‡é¢˜: {analysis['priority_recommendation']['title']}")
        print(analysis['priority_recommendation']['problem'][:150] + "...")
        
        print("\nâœ… æ—¥æŠ¥ç”Ÿæˆå®Œæˆï¼ˆä½¿ç”¨ä¸ªæ€§åŒ–AIåˆ†æï¼‰")

if __name__ == '__main__':
    main()
